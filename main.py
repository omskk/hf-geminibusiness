import json, time, hmac, hashlib, base64, os, asyncio, uuid, ssl, re
from datetime import datetime
from typing import List, Optional, Union, Dict, Any
import logging
from contextlib import asynccontextmanager

import httpx
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

from dotenv import load_dotenv
# Load .env file first
load_dotenv()

from database import db  # Import database instance
from cache_manager import init_session_pool, get_session_pool

# ---------- æ—¥å¿—é…ç½® ----------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger("gemini")

# ---------- é…ç½® ----------
API_KEY      = os.getenv("API_KEY")
# Fallsback ENV variables (customary support)
ENV_SECURE_C_SES = os.getenv("SECURE_C_SES")
ENV_HOST_C_OSES  = os.getenv("HOST_C_OSES")
ENV_CSESIDX      = os.getenv("CSESIDX")
ENV_CONFIG_ID    = os.getenv("CONFIG_ID")

PROXY        = os.getenv("PROXY") or None
TIMEOUT_SECONDS = 600 

# å¥åº·æ£€æŸ¥é…ç½®
HEALTH_CHECK_INTERVAL = int(os.getenv("HEALTH_CHECK_INTERVAL", "300"))  # 5åˆ†é’Ÿ
HEALTH_CHECK_ENABLED = os.getenv("HEALTH_CHECK_ENABLED", "true").lower() == "true"
HEALTH_CHECK_TIMEOUT = int(os.getenv("HEALTH_CHECK_TIMEOUT", "30"))  # 30ç§’è¶…æ—¶
HEALTH_CHECK_RETRY_COUNT = int(os.getenv("HEALTH_CHECK_RETRY_COUNT", "2"))  # é‡è¯•æ¬¡æ•°
HEALTH_CHECK_CONCURRENT_LIMIT = int(os.getenv("HEALTH_CHECK_CONCURRENT_LIMIT", "5"))  # å¹¶å‘é™åˆ¶
HEALTH_CHECK_AUTO_DISABLE = os.getenv("HEALTH_CHECK_AUTO_DISABLE", "true").lower() == "true"  # è‡ªåŠ¨ç¦ç”¨
HEALTH_CHECK_NETWORK_ERROR_THRESHOLD = int(os.getenv("HEALTH_CHECK_NETWORK_ERROR_THRESHOLD", "3"))  # ç½‘ç»œé”™è¯¯é˜ˆå€¼

# ä¼šè¯æ± é…ç½®
SESSION_POOL_CONFIG = {
    'CACHE_HOT_SIZE': int(os.getenv("CACHE_HOT_SIZE", "5000")),
    'CACHE_WARM_SIZE': int(os.getenv("CACHE_WARM_SIZE", "3000")),
    'CACHE_COLD_SIZE': int(os.getenv("CACHE_COLD_SIZE", "2000")),
    'SESSION_TTL': int(os.getenv("SESSION_TTL", "7200")),
    'CACHE_CLEANUP_INTERVAL': int(os.getenv("CACHE_CLEANUP_INTERVAL", "300")),
    'MEMORY_WARNING_THRESHOLD': float(os.getenv("MEMORY_WARNING_THRESHOLD", "0.8")),
    'MEMORY_CRITICAL_THRESHOLD': float(os.getenv("MEMORY_CRITICAL_THRESHOLD", "0.9"))
}

# ---------- æ¨¡å‹æ˜ å°„é…ç½® ----------
MODEL_MAPPING = {
    "gemini-auto": None,
    "gemini-2.5-flash": "gemini-2.5-flash",
    "gemini-2.5-pro": "gemini-2.5-pro",
    "gemini-3-flash-preview": "gemini-3-flash-preview",
    "gemini-3-pro-preview": "gemini-3-pro-preview"
}

# ---------- HTTP å®¢æˆ·ç«¯ ----------
http_client = httpx.AsyncClient(
    proxy=PROXY,
    verify=False,
    http2=False,
    timeout=httpx.Timeout(TIMEOUT_SECONDS, connect=60.0),
    limits=httpx.Limits(max_keepalive_connections=20, max_connections=50)
)

# ---------- è´¦å·æ± ç®¡ç† ----------

# ---------- å¥åº·æ£€æŸ¥å™¨ ----------
class HealthChecker:
    """è´¦å·å¥åº·æ£€æŸ¥å™¨"""
    
    # éœ€è¦è‡ªåŠ¨ç¦ç”¨çš„é”™è¯¯ç 
    AUTO_DISABLE_ERROR_CODES = [401, 403, 429]
    
    # éœ€è¦è‡ªåŠ¨ç¦ç”¨çš„é”™è¯¯å…³é”®è¯
    AUTO_DISABLE_ERROR_KEYWORDS = [
        "authentication failed",
        "unauthorized", 
        "forbidden",
        "rate limit",
        "quota exceeded",
        "account suspended",
        "invalid credentials",
        "token expired",
        "session expired"
    ]
    
    @staticmethod
    async def check_account_health(account) -> dict:
        """æ£€æŸ¥å•ä¸ªè´¦å·çš„å¥åº·çŠ¶æ€"""
        start_time = time.time()
        
        try:
            logger.info(f"ğŸ¥ å¼€å§‹æ£€æŸ¥è´¦å· [{account.id}] {account.name} çš„å¥åº·çŠ¶æ€")
            
            # å°è¯•è·å–JWT
            jwt = await account.get_jwt()
            
            # å°è¯•åˆ›å»ºæµ‹è¯•ä¼šè¯
            session_name = await create_google_session(account)
            
            # è®¡ç®—æ£€æŸ¥è€—æ—¶
            check_duration = round((time.time() - start_time) * 1000, 2)
            
            # æ›´æ–°å¥åº·çŠ¶æ€ä¸ºå¥åº·
            await db.update_health_status(account.id, "healthy")
            
            logger.info(f"âœ… è´¦å· [{account.id}] å¥åº·æ£€æŸ¥é€šè¿‡ï¼Œè€—æ—¶ {check_duration}ms")
            
            return {
                "status": "success",
                "account_id": account.id,
                "account_name": account.name,
                "message": "è´¦å·å¥åº·",
                "check_duration_ms": check_duration,
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except HTTPException as e:
            status_code = e.status_code
            error_msg = str(e)
            check_duration = round((time.time() - start_time) * 1000, 2)
            
            # ç›´æ¥ç¦ç”¨è´¦å·ï¼ˆæŒ‰ç”¨æˆ·è¦æ±‚ï¼‰
            reason = f"HEALTH_CHECK_{status_code}: {error_msg[:200]}"  # é™åˆ¶åŸå› é•¿åº¦
            await db.disable_account_with_reason(account.id, reason)
            logger.warning(f"ğŸš« è´¦å· [{account.id}] å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œå·²è‡ªåŠ¨ç¦ç”¨: {reason}")
            
            return {
                "status": "failed",
                "account_id": account.id,
                "account_name": account.name,
                "error_code": status_code,
                "message": f"è´¦å·è‡ªåŠ¨ç¦ç”¨: {error_msg}",
                "disabled": True,
                "check_duration_ms": check_duration,
                "timestamp": datetime.utcnow().isoformat()
            }
                
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸ - ç›´æ¥ç¦ç”¨è´¦å·ï¼ˆæŒ‰ç”¨æˆ·è¦æ±‚ï¼‰
            error_msg = str(e)
            check_duration = round((time.time() - start_time) * 1000, 2)
            
            reason = f"HEALTH_CHECK_EXCEPTION: {error_msg[:200]}"  # é™åˆ¶åŸå› é•¿åº¦
            await db.disable_account_with_reason(account.id, reason)
            logger.warning(f"ğŸš« è´¦å· [{account.id}] å¥åº·æ£€æŸ¥å¼‚å¸¸ï¼Œå·²è‡ªåŠ¨ç¦ç”¨: {reason}")
            
            return {
                "status": "failed",
                "account_id": account.id,
                "account_name": account.name,
                "message": f"è´¦å·è‡ªåŠ¨ç¦ç”¨: {error_msg}",
                "disabled": True,
                "check_duration_ms": check_duration,
                "timestamp": datetime.utcnow().isoformat()
            }
    
    @staticmethod
    async def check_account_with_timeout(account) -> dict:
        """å¸¦è¶…æ—¶çš„è´¦å·å¥åº·æ£€æŸ¥"""
        try:
            return await asyncio.wait_for(
                HealthChecker.check_account_health(account),
                timeout=HEALTH_CHECK_TIMEOUT
            )
        except asyncio.TimeoutError:
            check_duration = HEALTH_CHECK_TIMEOUT * 1000
            logger.warning(f"â° è´¦å· [{account.id}] å¥åº·æ£€æŸ¥è¶…æ—¶ ({HEALTH_CHECK_TIMEOUT}ç§’)")
            
            # æ£€æŸ¥ç½‘ç»œé”™è¯¯é˜ˆå€¼
            network_error_count = await db.increment_network_error_count(account.id)
            should_disable = network_error_count >= HEALTH_CHECK_NETWORK_ERROR_THRESHOLD
            
            if should_disable:
                reason = f"HEALTH_CHECK_TIMEOUT_{network_error_count}: è¿ç»­è¶…æ—¶{network_error_count}æ¬¡"
                await db.disable_account_with_reason(account.id, reason)
                await db.reset_network_error_count(account.id)  # é‡ç½®è®¡æ•°å™¨
                
                return {
                    "status": "failed",
                    "account_id": account.id,
                    "account_name": account.name,
                    "message": f"è´¦å·å› è¿ç»­è¶…æ—¶è¢«è‡ªåŠ¨ç¦ç”¨",
                    "disabled": True,
                    "check_duration_ms": check_duration,
                    "timestamp": datetime.utcnow().isoformat()
                }
            else:
                await db.update_health_status(account.id, "unhealthy")
                
                return {
                    "status": "failed",
                    "account_id": account.id,
                    "account_name": account.name,
                    "message": f"å¥åº·æ£€æŸ¥è¶…æ—¶ ({network_error_count}/{HEALTH_CHECK_NETWORK_ERROR_THRESHOLD})",
                    "disabled": False,
                    "check_duration_ms": check_duration,
                    "timestamp": datetime.utcnow().isoformat()
                }
    
    @staticmethod
    async def run_health_check_all():
        """è¿è¡Œæ‰€æœ‰è´¦å·çš„å¥åº·æ£€æŸ¥ï¼ˆå¹¶å‘ç‰ˆæœ¬ï¼‰"""
        logger.info("ğŸ¥ å¼€å§‹æ‰§è¡Œå…¨å±€å¥åº·æ£€æŸ¥...")
        
        # ä¿®æ”¹ï¼šåªæ£€æŸ¥æ•°æ®åº“ä¸­çŠ¶æ€ä¸ºæ­£å¸¸çš„è´¦å·
        accounts_to_check = await db.get_healthy_accounts_for_health_check()
        if not accounts_to_check:
            logger.info("ğŸ“­ æ²¡æœ‰éœ€è¦æ£€æŸ¥çš„è´¦å·")
            return []  # è¿”å›ç©ºåˆ—è¡¨è€Œä¸æ˜¯None
        
        logger.info(f"ğŸ“‹ å°†æ£€æŸ¥ {len(accounts_to_check)} ä¸ªè´¦å·ï¼Œå¹¶å‘é™åˆ¶: {HEALTH_CHECK_CONCURRENT_LIMIT}")
        
        results = []
        
        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°é‡
        semaphore = asyncio.Semaphore(HEALTH_CHECK_CONCURRENT_LIMIT)
        
        async def check_with_semaphore(account_data):
            async with semaphore:
                account = Account(account_data)
                try:
                    result = await HealthChecker.check_account_with_timeout(account)
                    return result
                except Exception as e:
                    # å…œåº•å¼‚å¸¸å¤„ç†
                    logger.error(f"âŒ è´¦å· [{account.id}] æ£€æŸ¥è¿‡ç¨‹å¼‚å¸¸: {e}")
                    return {
                        "status": "failed",
                        "account_id": account.id,
                        "account_name": account.name,
                        "message": f"æ£€æŸ¥è¿‡ç¨‹å¼‚å¸¸: {str(e)}",
                        "disabled": False,
                        "timestamp": datetime.utcnow().isoformat()
                    }
        
        # å¹¶å‘æ‰§è¡Œå¥åº·æ£€æŸ¥
        tasks = [check_with_semaphore(account_data) for account_data in accounts_to_check]
        
        # ä½¿ç”¨ asyncio.gather æ”¶é›†ç»“æœï¼Œå³ä½¿æœ‰éƒ¨åˆ†å¤±è´¥ä¹Ÿç»§ç»­
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"âŒ è´¦å·æ£€æŸ¥ä»»åŠ¡å¼‚å¸¸: {result}")
                processed_results.append({
                    "status": "failed",
                    "account_id": accounts_to_check[i].get("id", "unknown"),
                    "account_name": accounts_to_check[i].get("name", "unknown"),
                    "message": f"ä»»åŠ¡å¼‚å¸¸: {str(result)}",
                    "disabled": False,
                    "timestamp": datetime.utcnow().isoformat()
                })
            else:
                processed_results.append(result)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in processed_results if r["status"] == "success")
        failed_count = len(processed_results) - success_count
        disabled_count = sum(1 for r in processed_results if r.get("disabled", False))
        
        logger.info(f"ğŸ¥ å¥åº·æ£€æŸ¥å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}, ç¦ç”¨ {disabled_count}")
        
        return processed_results

# ---------- å·¥å…·å‡½æ•° ----------
def get_common_headers(jwt: str) -> dict:
    return {
        "accept": "*/*",
        "accept-encoding": "gzip, deflate, br, zstd",
        "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
        "authorization": f"Bearer {jwt}",
        "content-type": "application/json",
        "origin": "https://business.gemini.google",
        "referer": "https://business.gemini.google/",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
        "x-server-timeout": "1800",
        "sec-ch-ua": '"Chromium";v="124", "Google Chrome";v="124", "Not-A.Brand";v="99"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Windows"',
        "sec-fetch-dest": "empty",
        "sec-fetch-mode": "cors",
        "sec-fetch-site": "cross-site",
    }

def urlsafe_b64encode(data: bytes) -> str:
    return base64.urlsafe_b64encode(data).decode().rstrip("=")

def kq_encode(s: str) -> str:
    b = bytearray()
    for ch in s:
        v = ord(ch)
        if v > 255:
            b.append(v & 255)
            b.append(v >> 8)
        else:
            b.append(v)
    return urlsafe_b64encode(bytes(b))

def create_jwt(key_bytes: bytes, key_id: str, csesidx: str) -> str:
    now = int(time.time())
    header = {"alg": "HS256", "typ": "JWT", "kid": key_id}
    payload = {
        "iss": "https://business.gemini.google",
        "aud": "https://biz-discoveryengine.googleapis.com",
        "sub": f"csesidx/{csesidx}",
        "iat": now,
        "exp": now + 300,
        "nbf": now,
    }
    header_b64  = kq_encode(json.dumps(header, separators=(",", ":")))
    payload_b64 = kq_encode(json.dumps(payload, separators=(",", ":")))
    message     = f"{header_b64}.{payload_b64}"
    sig         = hmac.new(key_bytes, message.encode(), hashlib.sha256).digest()
    return f"{message}.{urlsafe_b64encode(sig)}"

# ---------- JWT ç®¡ç† (Per Account) ----------
class JWTManager:
    def __init__(self, account_data: dict) -> None:
        self.account = account_data
        self.jwt: str = ""
        self.expires: float = 0
        self._lock = asyncio.Lock()

    async def get(self) -> str:
        async with self._lock:
            if time.time() > self.expires:
                await self._refresh()
            return self.jwt

    async def _refresh(self) -> None:
        cookie = f"__Secure-C_SES={self.account['secure_c_ses']}"
        if self.account.get('host_c_oses'):
            cookie += f"; __Host-C_OSES={self.account['host_c_oses']}"
        
        logger.debug(f"ğŸ”‘ [{self.account['id']}] æ­£åœ¨åˆ·æ–° JWT...")
        try:
            r = await http_client.get(
                "https://business.gemini.google/auth/getoxsrf",
                params={"csesidx": self.account['csesidx']},
                headers={
                    "cookie": cookie,
                    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
                    "referer": "https://business.gemini.google/"
                },
            )
            if r.status_code != 200:
                logger.error(f"âŒ [{self.account['id']}] getoxsrf å¤±è´¥: {r.status_code} {r.text}")
                raise HTTPException(r.status_code, "getoxsrf failed")
            
            txt = r.text[4:] if r.text.startswith(")]}'") else r.text
            data = json.loads(txt)

            key_bytes = base64.urlsafe_b64decode(data["xsrfToken"] + "==")
            self.jwt     = create_jwt(key_bytes, data["keyId"], self.account['csesidx'])
            self.expires = time.time() + 270
            logger.info(f"âœ… [{self.account['id']}] JWT åˆ·æ–°æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ [{self.account['id']}] JWT Refresh Error: {e}")
            raise e

# ---------- è´¦å·ä¸ä¼šè¯ç®¡ç† ----------
class Account:
    def __init__(self, data: dict):
        self.id = data.get("id") or 0
        self.name = data.get("name") or f"Account-{self.id}"
        self.secure_c_ses = data["secure_c_ses"]
        self.host_c_oses = data.get("host_c_oses")
        self.csesidx = data["csesidx"]
        self.config_id = data["config_id"]
        self.is_active = data.get("is_active", True)
        
        self.jwt_mgr = JWTManager(data)
        self.lock = asyncio.Lock() # For account-level operations if needed

    async def get_jwt(self):
        return await self.jwt_mgr.get()

class AccountPool:
    def __init__(self):
        self.accounts: List[Account] = []
        self._current_index = 0
        self._lock = asyncio.Lock()

    async def load_accounts(self):
        try:
            await db.connect()
            rows = await db.fetch_active_accounts()
            if rows:
                self.accounts = [Account(row) for row in rows]
                logger.info(f"ğŸ“š å·²ä»æ•°æ®åº“åŠ è½½ {len(self.accounts)} ä¸ªè´¦å·")
            else:
                logger.info("âš ï¸ æ•°æ®åº“ä¸­æ— å¯ç”¨è´¦å·ï¼Œå°è¯•ä½¿ç”¨ç¯å¢ƒå˜é‡ fallback")
                await self._load_fallback()
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è´¦å·å¤±è´¥: {e}")
            await self._load_fallback()

    async def _load_fallback(self):
        if all([ENV_SECURE_C_SES, ENV_CSESIDX, ENV_CONFIG_ID]):
            fallback_data = {
                "id": 0,
                "name": "Env-Fallback",
                "secure_c_ses": ENV_SECURE_C_SES,
                "host_c_oses": ENV_HOST_C_OSES,
                "csesidx": ENV_CSESIDX,
                "config_id": ENV_CONFIG_ID
            }
            self.accounts = [Account(fallback_data)]
            logger.info("âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡ fallback è´¦å·")
        else:
            logger.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨è´¦å·é…ç½®")

    async def get_next_account(self) -> Optional[Account]:
        """Failover Mode: Always return the first active account."""
        async with self._lock:
            if not self.accounts: return None

            # é‡æ–°ä»æ•°æ®åº“åŠ è½½æœ€æ–°çš„è´¦å·çŠ¶æ€ï¼Œç¡®ä¿è·å–æœ€æ–°çš„ is_active çŠ¶æ€
            try:
                await db.connect()
                active_accounts_data = await db.fetch_active_accounts()
                if not active_accounts_data:
                    logger.warning("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰æ´»è·ƒè´¦å·")
                    return None
                
                # æ›´æ–°å†…å­˜ä¸­çš„è´¦å·åˆ—è¡¨å’ŒçŠ¶æ€
                self.accounts = [Account(data) for data in active_accounts_data]
                logger.info(f"ğŸ”„ å·²åˆ·æ–°è´¦å·æ± ï¼Œå½“å‰æœ‰ {len(self.accounts)} ä¸ªæ´»è·ƒè´¦å·")
                
                # è¿”å›ç¬¬ä¸€ä¸ªæ´»è·ƒè´¦å·
                if self.accounts:
                    account = self.accounts[0]
                    logger.info(f"ğŸ›¡ï¸ [Primary/Sticky] Using Account: [{account.id}] {account.name}")
                    return account
                else:
                    return None
                    
            except Exception as e:
                logger.error(f"âŒ åˆ·æ–°è´¦å·æ± å¤±è´¥: {e}")
                # å¦‚æœåˆ·æ–°å¤±è´¥ï¼Œä½¿ç”¨å†…å­˜ä¸­çš„è´¦å·åˆ—è¡¨ï¼Œä½†è¦æ£€æŸ¥ is_active çŠ¶æ€
                for acc in self.accounts:
                    if acc.is_active:
                        logger.info(f"ğŸ›¡ï¸ [Fallback] Using Account: [{acc.id}] {acc.name}")
                        return acc
                return None

    async def ensure_account_availability(self) -> bool:
        """ç¡®ä¿æœ‰å¯ç”¨çš„æ´»è·ƒè´¦å·"""
        try:
            await db.connect()
            active_accounts_data = await db.fetch_active_accounts()
            return len(active_accounts_data) > 0
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥è´¦å·å¯ç”¨æ€§å¤±è´¥: {e}")
            return False

    def get_account_by_id(self, account_id: int) -> Optional[Account]:
        for acc in self.accounts:
            if acc.id == account_id:
                return acc
        return None

account_pool = AccountPool()

# ç”¨æˆ·æ¨¡å‹åå¥½ç¼“å­˜ (Model Stickiness)
# Key: client_ip
# Value: last_stream_model_name
USER_MODEL_PREF: Dict[str, str] = {}
GLOBAL_LAST_MODEL_NAME: Optional[str] = None

async def create_google_session(account: Account) -> str:
    jwt = await account.get_jwt()
    headers = get_common_headers(jwt)
    body = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "createSessionRequest": {
            "session": {"name": "", "displayName": ""}
        }
    }
    
    logger.debug(f"ğŸŒ [{account.name}] ç”³è¯·æ–° Session...")
    r = await http_client.post(
        "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetCreateSession",
        headers=headers,
        json=body,
    )
    if r.status_code != 200:
        logger.error(f"âŒ createSession å¤±è´¥: {r.status_code} {r.text}")
        raise HTTPException(r.status_code, "createSession failed")
    sess_name = r.json()["session"]["name"]
    return sess_name

async def upload_context_file(account: Account, session_name: str, mime_type: str, base64_content: str) -> str:
    """ä¸Šä¼ æ–‡ä»¶åˆ°æŒ‡å®š Sessionï¼Œè¿”å› fileId"""
    jwt = await account.get_jwt()
    headers = get_common_headers(jwt)
    
    # ç”Ÿæˆéšæœºæ–‡ä»¶å
    ext = mime_type.split('/')[-1] if '/' in mime_type else "bin"
    file_name = f"upload_{int(time.time())}_{uuid.uuid4().hex[:6]}.{ext}"

    body = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "addContextFileRequest": {
            "name": session_name,
            "fileName": file_name,
            "mimeType": mime_type,
            "fileContents": base64_content
        }
    }

    logger.info(f"ğŸ“¤ [{account.name}] ä¸Šä¼ å›¾ç‰‡ [{mime_type}] åˆ° Session...")
    r = await http_client.post(
        "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetAddContextFile",
        headers=headers,
        json=body,
    )

    if r.status_code != 200:
        logger.error(f"âŒ ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {r.status_code} {r.text}")
        raise HTTPException(r.status_code, f"Upload failed: {r.text}")
    
    data = r.json()
    file_id = data.get("addContextFileResponse", {}).get("fileId")
    logger.info(f"âœ… å›¾ç‰‡ä¸Šä¼ æˆåŠŸ, ID: {file_id}")
    return file_id

# ---------- API Key éªŒè¯ ----------
async def verify_api_key(request: Request) -> None:
    if API_KEY is None: return
    auth_header = request.headers.get("authorization")
    if not auth_header or not auth_header.startswith("Bearer ") or auth_header[7:] != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid API key")

# ---------- æ¶ˆæ¯å¤„ç†é€»è¾‘ ----------
def get_conversation_key(messages: List[dict]) -> str:
    if not messages: return "empty"
    # ä»…ä½¿ç”¨ç¬¬ä¸€æ¡æ¶ˆæ¯çš„å†…å®¹ç”ŸæˆæŒ‡çº¹ï¼Œå¿½ç•¥å›¾ç‰‡æ•°æ®é˜²æ­¢æŒ‡çº¹è¿‡å¤§
    first_msg = messages[0].copy()
    if isinstance(first_msg.get("content"), list):
        # å¦‚æœç¬¬ä¸€æ¡æ˜¯å¤šæ¨¡æ€ï¼Œåªå–æ–‡æœ¬éƒ¨åˆ†åš Hash
        text_part = "".join([x["text"] for x in first_msg["content"] if x["type"] == "text"])
        first_msg["content"] = text_part
    
    key_str = json.dumps(first_msg, sort_keys=True)
    return hashlib.md5(key_str.encode()).hexdigest()

def parse_last_message(messages: List['Message']):
    """è§£ææœ€åä¸€æ¡æ¶ˆæ¯ï¼Œåˆ†ç¦»æ–‡æœ¬å’Œå›¾ç‰‡"""
    if not messages:
        return "", []
    
    last_msg = messages[-1]
    content = last_msg.content
    
    text_content = ""
    images = [] # List of {"mime": str, "data": str_base64}

    if isinstance(content, str):
        text_content = content
    elif isinstance(content, list):
        for part in content:
            if part.get("type") == "text":
                text_content += part.get("text", "")
            elif part.get("type") == "image_url":
                url = part.get("image_url", {}).get("url", "")
                # è§£æ Data URI: data:image/png;base64,xxxxxx
                match = re.match(r"data:(image/[^;]+);base64,(.+)", url)
                if match:
                    images.append({"mime": match.group(1), "data": match.group(2)})
                else:
                    logger.warning(f"âš ï¸ æš‚ä¸æ”¯æŒé Base64 å›¾ç‰‡é“¾æ¥: {url[:30]}...")

    return text_content, images

def build_full_context_text(messages: List['Message']) -> str:
    """ä»…æ‹¼æ¥å†å²æ–‡æœ¬ï¼Œå›¾ç‰‡åªå¤„ç†å½“æ¬¡è¯·æ±‚çš„ã€‚å…¼å®¹å¤„ç† Tool Messagesã€‚"""
    prompt = ""
    for msg in messages:
        role = msg.role
        if role in ["user", "system"]:
            role_name = "User"
        elif role == "assistant":
            role_name = "Assistant"
        elif role == "tool":
            role_name = "Tool Output"
        else:
            role_name = "User" # Fallback

        content_str = ""
        if msg.content:
            if isinstance(msg.content, str):
                content_str = msg.content
            elif isinstance(msg.content, list):
                for part in msg.content:
                    if part.get("type") == "text":
                        content_str += part.get("text", "")
                    elif part.get("type") == "image_url":
                        content_str += "[å›¾ç‰‡]"
        
        # Helper for tool calls in assistant message
        if msg.tool_calls:
            for tc in msg.tool_calls:
                func_name = tc.get("function", {}).get("name", "unknown")
                args = tc.get("function", {}).get("arguments", "{}")
                content_str += f"\n[Call Tool: {func_name}({args})]"

        prompt += f"{role_name}: {content_str}\n\n"
    return prompt

# ---------- å®šæ—¶å¥åº·æ£€æŸ¥ä»»åŠ¡ ----------
async def run_startup_health_check():
    """å¯åŠ¨æ—¶æ‰§è¡Œä¸€æ¬¡å¥åº·æ£€æŸ¥"""
    if not HEALTH_CHECK_ENABLED:
        logger.info("ğŸ¥ å¯åŠ¨å¥åº·æ£€æŸ¥å·²ç¦ç”¨")
        return
    
    logger.info("ğŸ¥ æ‰§è¡Œå¯åŠ¨æ—¶å¥åº·æ£€æŸ¥...")
    try:
        results = await HealthChecker.run_health_check_all()
        success_count = sum(1 for r in results if r["status"] == "success")
        failed_count = len(results) - success_count
        disabled_count = sum(1 for r in results if r.get("disabled", False))
        logger.info(f"ğŸ¥ å¯åŠ¨å¥åº·æ£€æŸ¥å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}, ç¦ç”¨ {disabled_count}")
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨å¥åº·æ£€æŸ¥å¤±è´¥: {e}")

async def scheduled_health_check():
    """å®šæ—¶å¥åº·æ£€æŸ¥ä»»åŠ¡"""
    if not HEALTH_CHECK_ENABLED:
        logger.info("ğŸ¥ å®šæ—¶å¥åº·æ£€æŸ¥å·²ç¦ç”¨")
        return
    
    logger.info(f"ğŸ¥ å®šæ—¶å¥åº·æ£€æŸ¥ä»»åŠ¡å¯åŠ¨ï¼Œé—´éš”: {HEALTH_CHECK_INTERVAL}ç§’")
    
    while True:
        try:
            await asyncio.sleep(HEALTH_CHECK_INTERVAL)
            await HealthChecker.run_health_check_all()
        except asyncio.CancelledError:
            logger.info("ğŸ¥ å®šæ—¶å¥åº·æ£€æŸ¥ä»»åŠ¡å·²åœæ­¢")
            break
        except Exception as e:
            logger.error(f"âŒ å®šæ—¶å¥åº·æ£€æŸ¥ä»»åŠ¡å¼‚å¸¸: {e}")
            # ç»§ç»­è¿è¡Œï¼Œä¸ä¸­æ–­å®šæ—¶ä»»åŠ¡"

# ---------- è´¦å·è‡ªåŠ¨ç¦ç”¨å·¥å…·å‡½æ•° ----------
def should_disable_account_for_error(error: Exception) -> tuple[bool, str]:
    """
    åˆ¤æ–­æ˜¯å¦éœ€è¦å› é”™è¯¯è€Œç¦ç”¨è´¦å·ï¼Œå¹¶è¿”å›ç¦ç”¨åŸå› 
    
    Args:
        error: æ•è·çš„å¼‚å¸¸å¯¹è±¡
        
    Returns:
        tuple[bool, str]: (æ˜¯å¦ç¦ç”¨, ç¦ç”¨åŸå› )
    """
    disable_reason = ""
    
    # æ£€æŸ¥å¼‚å¸¸ç±»å‹
    if isinstance(error, HTTPException):
        status_code = error.status_code
        error_detail = str(error)
        if status_code in [401, 403, 302, 429]:
            disable_reason = f"HTTP_{status_code}: {error_detail[:200]}"
            return True, disable_reason
    else:
        # æ£€æŸ¥å¼‚å¸¸ä¿¡æ¯
        error_detail = str(error)
        error_lower = error_detail.lower()
        if any(keyword in error_lower for keyword in [
            "authentication failed",
            "unauthorized", 
            "forbidden",
            "session expired",
            "token expired",
            "invalid credentials",
            "getoxsrf failed",
            "302"
        ]):
            disable_reason = f"EXCEPTION: {error_detail[:200]}"
            return True, disable_reason
    
    return False, disable_reason

async def auto_disable_account_if_needed(account: Account, error: Exception, session_pool, error_context: str = "API_CALL"):
    """
    æ ¹æ®é”™è¯¯è‡ªåŠ¨ç¦ç”¨è´¦å·ï¼ˆå¦‚æœéœ€è¦ï¼‰
    
    Args:
        account: è´¦å·å¯¹è±¡
        error: æ•è·çš„å¼‚å¸¸å¯¹è±¡
        session_pool: ä¼šè¯æ± å¯¹è±¡
        error_context: é”™è¯¯ä¸Šä¸‹æ–‡æ ‡è¯†ï¼ˆå¦‚ "SESSION_CREATE", "API_CALL" ç­‰ï¼‰
    """
    if not account or account.id <= 0:
        return
    
    should_disable, base_reason = should_disable_account_for_error(error)
    if should_disable:
        disable_reason = f"{error_context}_{base_reason}"
        logger.warning(f"ğŸš« è´¦å· [{account.id}] {error_context.lower()}å¤±è´¥ï¼Œè‡ªåŠ¨ç¦ç”¨: {disable_reason}")
        try:
            await db.disable_account_with_reason(account.id, disable_reason)
            await account_pool.load_accounts()  # é‡æ–°åŠ è½½è´¦å·æ± 
            # æ¸…ç†è¯¥è´¦å·çš„æ‰€æœ‰ä¼šè¯
            session_pool.clear_account_sessions(account.id)
            logger.info(f"âœ… å·²è‡ªåŠ¨ç¦ç”¨è´¦å· [{account.id}] å¹¶æ¸…ç†ç›¸å…³ä¼šè¯")
        except Exception as db_err:
            logger.error(f"âŒ æ›´æ–°æ•°æ®åº“å¤±è´¥: {db_err}")

# ---------- FastAPI App & Lifespan ----------
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await account_pool.load_accounts()
    
    # åˆå§‹åŒ–ä¼šè¯æ± 
    session_pool = init_session_pool(SESSION_POOL_CONFIG)
    await session_pool.start()
    app.state.session_pool = session_pool
    logger.info("ğŸš€ ä¼šè¯æ± å·²åˆå§‹åŒ–")
    
    # å¯åŠ¨æ—¶æ‰§è¡Œå¥åº·æ£€æŸ¥
    if HEALTH_CHECK_ENABLED:
        await run_startup_health_check()
    
    # å¯åŠ¨å®šæ—¶å¥åº·æ£€æŸ¥ä»»åŠ¡
    if HEALTH_CHECK_ENABLED:
        health_check_task = asyncio.create_task(scheduled_health_check())
        app.state.health_check_task = health_check_task
        logger.info("ğŸ¥ å®šæ—¶å¥åº·æ£€æŸ¥ä»»åŠ¡å·²å¯åŠ¨")
    
    yield
    
    # Shutdown
    if HEALTH_CHECK_ENABLED and hasattr(app.state, 'health_check_task'):
        app.state.health_check_task.cancel()
        try:
            await app.state.health_check_task
        except asyncio.CancelledError:
            pass
        logger.info("ğŸ¥ å®šæ—¶å¥åº·æ£€æŸ¥ä»»åŠ¡å·²åœæ­¢")
    
    # åœæ­¢ä¼šè¯æ± 
    if hasattr(app.state, 'session_pool'):
        await app.state.session_pool.stop()
        logger.info("ğŸ›‘ ä¼šè¯æ± å·²åœæ­¢")
    
    await db.disconnect()

# ---------- OpenAI å…¼å®¹æ¥å£ ----------
app = FastAPI(title="Gemini-Business OpenAI Gateway", lifespan=lifespan)
# Mount static files for Admin UI
app.mount("/admin", StaticFiles(directory="static/admin", html=True), name="static")

# Admin API Models
class AccountCreate(BaseModel):
    name: str = "New Account"
    secure_c_ses: str
    host_c_oses: Optional[str] = None
    csesidx: str
    config_id: str

class AccountUpdate(BaseModel):
    name: Optional[str] = None
    secure_c_ses: Optional[str] = None
    host_c_oses: Optional[str] = None
    csesidx: Optional[str] = None
    config_id: Optional[str] = None
    is_active: Optional[bool] = None

# Admin API Routes
from fastapi import Depends

@app.get("/api/admin/accounts", dependencies=[Depends(verify_api_key)])
async def admin_list_accounts():
    return await db.get_all_accounts()

@app.post("/api/admin/accounts", dependencies=[Depends(verify_api_key)])
async def admin_add_account(acc: AccountCreate):
    await db.add_account(
        name=acc.name,
        secure_c_ses=acc.secure_c_ses,
        host_c_oses=acc.host_c_oses,
        csesidx=acc.csesidx,
        config_id=acc.config_id
    )
    await account_pool.load_accounts() # Refresh pool
    return {"status": "ok"}

@app.put("/api/admin/accounts/{id}", dependencies=[Depends(verify_api_key)])
async def admin_update_account(id: int, acc: AccountUpdate):
    data = acc.dict(exclude_unset=True)
    if not data: return {"status": "no change"}
    await db.update_account(id, data)
    await account_pool.load_accounts() # Refresh pool
    return {"status": "ok"}

@app.delete("/api/admin/accounts/{id}", dependencies=[Depends(verify_api_key)])
async def admin_delete_account(id: int):
    await db.delete_account(id)
    await account_pool.load_accounts() # Refresh pool
    return {"status": "ok"}

@app.post("/api/admin/accounts/{id}/test", dependencies=[Depends(verify_api_key)])
async def admin_test_account(id: int):
    """æµ‹è¯•æŒ‡å®šè´¦å·æ˜¯å¦å¯ç”¨"""
    account = account_pool.get_account_by_id(id)
    if not account:
        raise HTTPException(status_code=404, detail="Account not found")
    
    try:
        # å°è¯•è·å– JWT
        jwt = await account.get_jwt()
        
        # å°è¯•åˆ›å»º Session
        session_name = await create_google_session(account)
        
        # æ¸…ç†æµ‹è¯• Session
        return {
            "status": "success",
            "message": "è´¦å·æµ‹è¯•æˆåŠŸ",
            "account_id": id,
            "account_name": account.name
        }
    except Exception as e:
        status_code = e.status_code if isinstance(e, HTTPException) else 500
        error_msg = str(e)
        
        # å¦‚æœæ˜¯ 401 é”™è¯¯ï¼Œè‡ªåŠ¨ç¦ç”¨è´¦å·
        if status_code == 401:
            reason = f"API_TEST_401: {error_msg}"
            await db.disable_account_with_reason(id, reason)
            await account_pool.load_accounts()
            logger.warning(f"ğŸš« æµ‹è¯•å¤±è´¥ï¼Œå·²è‡ªåŠ¨ç¦ç”¨è´¦å· [{id}]: {reason}")
        
        raise HTTPException(
            status_code=400,
            detail={
                "status": "failed",
                "message": f"è´¦å·æµ‹è¯•å¤±è´¥: {error_msg}",
                "account_id": id,
                "error_code": status_code
            }
        )

# ---------- å¥åº·æ£€æŸ¥APIç«¯ç‚¹ ----------
@app.post("/api/admin/health-check", dependencies=[Depends(verify_api_key)])
async def admin_run_health_check():
    """æ‰‹åŠ¨è§¦å‘å…¨å±€å¥åº·æ£€æŸ¥"""
    try:
        results = await HealthChecker.run_health_check_all()
        return {
            "status": "completed",
            "message": "å¥åº·æ£€æŸ¥å®Œæˆ",
            "results": results,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥æ‰§è¡Œå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¥åº·æ£€æŸ¥æ‰§è¡Œå¤±è´¥: {str(e)}")

@app.post("/api/admin/accounts/{id}/health-check", dependencies=[Depends(verify_api_key)])
async def admin_check_account_health(id: int):
    """æ£€æŸ¥æŒ‡å®šè´¦å·çš„å¥åº·çŠ¶æ€"""
    # ä»æ•°æ®åº“ç›´æ¥è·å–è´¦å·ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ä»account_poolï¼ˆå› ä¸ºè¢«ç¦ç”¨çš„è´¦å·ä¸åœ¨poolä¸­ï¼‰
    all_accounts = await db.get_all_accounts()
    account_data = next((acc for acc in all_accounts if acc['id'] == id), None)
    
    if not account_data:
        raise HTTPException(status_code=404, detail="Account not found")
    
    # åˆ›å»ºAccountå¯¹è±¡è¿›è¡Œå¥åº·æ£€æŸ¥
    account = Account(account_data)
    result = await HealthChecker.check_account_health(account)
    return result

@app.get("/api/admin/health-status", dependencies=[Depends(verify_api_key)])
async def admin_get_health_status():
    """è·å–æ‰€æœ‰è´¦å·çš„å¥åº·çŠ¶æ€"""
    try:
        accounts = await db.get_all_accounts()
        summary = await db.get_health_summary()
        
        return {
            "summary": summary,
            "accounts": accounts,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"âŒ è·å–å¥åº·çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å¥åº·çŠ¶æ€å¤±è´¥: {str(e)}")

@app.post("/api/admin/accounts/{id}/enable", dependencies=[Depends(verify_api_key)])
async def admin_enable_account(id: int):
    """æ‰‹åŠ¨å¯ç”¨è´¦å·"""
    try:
        await db.enable_account(id)
        await account_pool.load_accounts()
        
        return {
            "status": "success",
            "message": f"è´¦å· [{id}] å·²å¯ç”¨",
            "account_id": id
        }
    except Exception as e:
        logger.error(f"âŒ å¯ç”¨è´¦å·å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¯ç”¨è´¦å·å¤±è´¥: {str(e)}")

# ---------- ç¼“å­˜ç®¡ç†APIç«¯ç‚¹ ----------
@app.get("/api/admin/cache/stats", dependencies=[Depends(verify_api_key)])
async def admin_get_cache_stats():
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    try:
        session_pool = get_session_pool()
        if not session_pool:
            raise HTTPException(status_code=503, detail="ä¼šè¯æ± æœªåˆå§‹åŒ–")
        
        stats = session_pool.get_detailed_stats()
        return {
            "status": "success",
            "data": stats,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"âŒ è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {str(e)}")

@app.post("/api/admin/cache/clear", dependencies=[Depends(verify_api_key)])
async def admin_clear_cache(account_id: Optional[int] = None):
    """æ¸…ç†ç¼“å­˜"""
    try:
        session_pool = get_session_pool()
        if not session_pool:
            raise HTTPException(status_code=503, detail="ä¼šè¯æ± æœªåˆå§‹åŒ–")
        
        if account_id:
            # æ¸…ç†æŒ‡å®šè´¦å·çš„ä¼šè¯
            cleared = session_pool.clear_account_sessions(account_id)
            message = f"å·²æ¸…ç†è´¦å· [{account_id}] çš„ {cleared} ä¸ªä¼šè¯"
        else:
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            session_pool.hot_cache.clear()
            session_pool.warm_cache.clear()
            session_pool.cold_cache.clear()
            message = "å·²æ¸…ç†æ‰€æœ‰ç¼“å­˜"
        
        logger.info(f"ğŸ§¹ {message}")
        
        return {
            "status": "success",
            "message": message,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}")

@app.post("/api/admin/cache/cleanup", dependencies=[Depends(verify_api_key)])
async def admin_force_cleanup():
    """å¼ºåˆ¶æ‰§è¡Œç¼“å­˜æ¸…ç†"""
    try:
        session_pool = get_session_pool()
        if not session_pool:
            raise HTTPException(status_code=503, detail="ä¼šè¯æ± æœªåˆå§‹åŒ–")
        
        await session_pool._perform_cleanup()
        
        return {
            "status": "success",
            "message": "å¼ºåˆ¶æ¸…ç†å·²å®Œæˆ",
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"âŒ å¼ºåˆ¶æ¸…ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¼ºåˆ¶æ¸…ç†å¤±è´¥: {str(e)}")

class Message(BaseModel):
    role: str
    content: Union[str, List[Dict[str, Any]], None] = None
    name: Optional[str] = None
    tool_calls: Optional[List[Dict[str, Any]]] = None
    tool_call_id: Optional[str] = None

class ChatRequest(BaseModel):
    model: str = "gemini-auto"
    messages: List[Message]
    stream: bool = False
    temperature: Optional[float] = 0.7
    top_p: Optional[float] = 1.0
    # OpenAI Compatibility Fields (Optional)
    tools: Optional[List[Dict[str, Any]]] = None
    tool_choice: Optional[Union[str, Dict[str, Any]]] = None
    max_tokens: Optional[int] = None
    n: Optional[int] = 1
    presence_penalty: Optional[float] = 0
    frequency_penalty: Optional[float] = 0
    stop: Optional[Union[str, List[str]]] = None

def create_chunk(id: str, created: int, model: str, delta: dict, finish_reason: Union[str, None]) -> str:
    chunk = {
        "id": id,
        "object": "chat.completion.chunk",
        "created": created,
        "model": model,
        "choices": [{
            "index": 0,
            "delta": delta,
            "finish_reason": finish_reason
        }]
    }
    return json.dumps(chunk)

@app.get("/v1/models")
async def list_models(request: Request):
    await verify_api_key(request)
    data = []
    now = int(time.time())
    for m in MODEL_MAPPING.keys():
        data.append({
            "id": m,
            "object": "model",
            "created": now,
            "owned_by": "google",
            "permission": []
        })
    return {"object": "list", "data": data}

@app.get("/health")
async def health():
    session_pool = get_session_pool()
    cache_stats = None
    if session_pool:
        metrics = session_pool.get_metrics()
        cache_stats = {
            "total_sessions": metrics.total_sessions,
            "hit_rate": round(metrics.hit_rate, 2),
            "memory_usage_mb": round(metrics.memory_usage_mb, 2)
        }
    
    return {
        "status": "ok", 
        "time": datetime.utcnow().isoformat(),
        "accounts_loaded": len(account_pool.accounts),
        "cache_stats": cache_stats
    }

@app.post("/v1/chat/completions")
async def chat(req: ChatRequest, request: Request):
    await verify_api_key(request)
    # 1. æ¨¡å‹æ ¡éªŒ
    # æ¨æ–­è¯·æ±‚æ„å›¾ (Intent Inference)
    intent = "ğŸ’¬ ä¸»åŠ¨å¯¹è¯ (Chat)" if req.stream else "ğŸ¤– åå°ä»»åŠ¡ (Background/Title)"
    
    # DEBUG: Log raw received model with Intent
    logger.info(f"ğŸ“¨ è¯·æ±‚æ”¶åˆ° | ç±»å‹: {intent} | æ¨¡å‹: [{req.model}] | æµå¼: {req.stream}")
    
    # --- æ¨¡å‹ç²˜æ€§ä¸ä¸€è‡´æ€§ç­–ç•¥ (Model Stickiness) ---
    # ç­–ç•¥ï¼šä»¥æµå¼è¯·æ±‚(Stream=True)ä¸ºå‡†ï¼Œå› ä¸ºé‚£æ˜¯ç”¨æˆ·æ­£åœ¨è¿›è¡Œçš„çœŸå®å¯¹è¯ã€‚
    # éæµå¼(Stream=False)é€šå¸¸æ˜¯åå°ä»»åŠ¡(å¦‚æ ‡é¢˜ç”Ÿæˆ/æ‘˜è¦)ï¼Œå¾€å¾€ä½¿ç”¨é™çº§æ¨¡å‹(2.5)ã€‚
    # æˆ‘ä»¬è®°å½•ç”¨æˆ·æœ€åä¸€æ¬¡æµå¼è¯·æ±‚ä½¿ç”¨çš„æ¨¡å‹ï¼Œå¹¶å¼ºåˆ¶åç»­çš„éæµå¼è¯·æ±‚ä¿æŒä¸€è‡´ã€‚
    
    client_ip = request.client.host if request.client else "global"
    
    global GLOBAL_LAST_MODEL_NAME
    
    if req.stream:
        # ç”¨æˆ·æ˜¾å¼å‘èµ·å¯¹è¯ -> æ›´æ–°é¦–é€‰æ¨¡å‹è®°å½•
        USER_MODEL_PREF[client_ip] = req.model
        GLOBAL_LAST_MODEL_NAME = req.model
    else:
        # åå°ä»»åŠ¡ -> æ£€æŸ¥æ˜¯å¦é€šè¿‡
        preferred = USER_MODEL_PREF.get(client_ip)
        if not preferred and GLOBAL_LAST_MODEL_NAME:
            preferred = GLOBAL_LAST_MODEL_NAME
        
        if preferred and req.model != preferred:
             # å¦‚æœåå°è¯·æ±‚çš„æ¨¡å‹(å¦‚2.5)ä¸ç”¨æˆ·é¦–é€‰(å¦‚3)ä¸ä¸€è‡´ï¼Œå¼ºåˆ¶å‡çº§
             # ç‰¹ä¾‹ï¼šå¦‚æœç”¨æˆ·çœŸçš„æƒ³ç”¨2.5å‘éæµå¼ï¼Œè¿™é‡Œä¼šè¢«è¯¯ä¼¤ï¼Œä½†æƒè¡¡ä¹‹ä¸‹ï¼Œä¸€è‡´æ€§ä¼˜å…ˆ
             if "gemini-2.5" in req.model and "gemini-3" in preferred:
                 logger.info(f"âœ¨ [è‡ªåŠ¨å‡çº§] æ£€æµ‹åˆ°åå°é™çº§è¯·æ±‚ ({req.model}) -> å·²è‡ªåŠ¨ä¿®æ­£ä¸ºç”¨æˆ·é¦–é€‰ ({preferred})")
                 req.model = preferred

    if req.model not in MODEL_MAPPING:
        # Auto-map common aliases if needed, but for now strict check
        raise HTTPException(status_code=404, detail=f"Model '{req.model}' not found.")

    # 1.1 Compatibility Warning
    if req.tools:
        logger.warning(f"âš ï¸ å·¥å…·è°ƒç”¨è¢«å¿½ç•¥: ä¸Šæ¸¸ Gemini Widget æ¥å£æš‚ä¸æ”¯æŒ Client-Side Tools")

    # 2. è§£æè¯·æ±‚å†…å®¹
    last_text, current_images = parse_last_message(req.messages)
    
    # 3. é”šå®š Session
    # Fix Pydantic V2 deprecation warning
    conv_key = get_conversation_key([m.model_dump() for m in req.messages])
    
    # ä½¿ç”¨æ–°çš„ä¼šè¯æ± 
    session_pool = get_session_pool()
    if not session_pool:
        raise HTTPException(status_code=503, detail="ä¼šè¯æ± æœªåˆå§‹åŒ–")
    
    cached_session = session_pool.get_session(conv_key)
    
    account: Optional[Account] = None
    google_session: str = ""
    is_retry_mode = False

    # 3.1 å°è¯•ä»ç¼“å­˜æ¢å¤
    if cached_session:
        account = account_pool.get_account_by_id(cached_session.account_id)
        
        # æ£€æŸ¥è´¦å·æ˜¯å¦ä»ç„¶å¯ç”¨ï¼ˆæ´»è·ƒä¸”å¥åº·ï¼‰
        if account and await db.fetch_active_accounts() and any(acc['id'] == cached_session.account_id for acc in await db.fetch_active_accounts()):
            google_session = cached_session.session_id
            text_to_send = last_text
            logger.info(f"â™»ï¸ å»¶ç»­æ—§å¯¹è¯ [{req.model}][Acc:{account.id}]: {google_session[-12:]}")
        else:
            logger.warning(f"âš ï¸ ç¼“å­˜è´¦å· ID {cached_session.account_id} ä¸å¯ç”¨ï¼Œå¼ºåˆ¶å¼€å¯æ–°å¯¹è¯")
            cached_session = None # Treat as new

    # 3.2 å¼€å¯æ–°ä¼šè¯ (å¦‚æœéœ€è¦)
    if not cached_session:
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ´»è·ƒè´¦å·
        if not await account_pool.ensure_account_availability():
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„æ´»è·ƒè´¦å·")
            raise HTTPException(status_code=503, detail="No active accounts available")
        
        account = await account_pool.get_next_account()
        if not account:
            raise HTTPException(status_code=503, detail="No active accounts available")
        
        logger.info(f"ğŸ›¡ï¸ [Primary/Sticky] Using Account: [{account.id}] {account.name}")
        logger.info(f"ğŸ†• å¼€å¯æ–°å¯¹è¯ [{req.model}][Acc:{account.id}]")
        try:
            google_session = await create_google_session(account)
            # æ–°å¯¹è¯ä½¿ç”¨å…¨é‡æ–‡æœ¬ä¸Šä¸‹æ–‡ (å›¾ç‰‡åªä¼ å½“å‰çš„)
            text_to_send = build_full_context_text(req.messages)
            
            # å­˜å‚¨åˆ°ä¼šè¯æ± 
            session_pool.put_session(conv_key, google_session, account.id)
            is_retry_mode = True
        except Exception as e:
            logger.error(f"âŒ å¼€å¯ä¼šè¯å¤±è´¥: {e}")
            
            # ğŸ”¥ ä½¿ç”¨é€šç”¨å‡½æ•°å¤„ç†è‡ªåŠ¨ç¦ç”¨
            await auto_disable_account_if_needed(account, e, session_pool, "SESSION_CREATE")
            
            raise HTTPException(status_code=500, detail=f"Failed to create session: {e}")

    chat_id = f"chatcmpl-{uuid.uuid4()}"
    created_time = int(time.time())

    # å°è£…ç”Ÿæˆå™¨ (å«å›¾ç‰‡ä¸Šä¼ å’Œé‡è¯•é€»è¾‘)
    async def response_wrapper():
        retry_count = 0
        max_retries = 2
        
        # Increment Request Tracking (Once per logical request)
        if account and account.id > 0:
            asyncio.create_task(db.increment_account_usage(account.id))
        
        current_text = text_to_send
        current_retry_mode = is_retry_mode
        
        # Important: Capture mutable variables for retry logic
        current_sess = google_session
        current_acc = account
        current_file_ids = []

        while retry_count <= max_retries:
            try:
                # A. å¦‚æœæœ‰å›¾ç‰‡ä¸”è¿˜æ²¡ä¸Šä¼ åˆ°å½“å‰ Sessionï¼Œå…ˆä¸Šä¼ 
                if current_images and not current_file_ids:
                    for img in current_images:
                        fid = await upload_context_file(current_acc, current_sess, img["mime"], img["data"])
                        current_file_ids.append(fid)

                # B. å‡†å¤‡æ–‡æœ¬ (é‡è¯•æ¨¡å¼ä¸‹å‘å…¨æ–‡)
                if current_retry_mode:
                    current_text = build_full_context_text(req.messages)

                # C. å‘èµ·å¯¹è¯
                async for chunk in stream_chat_generator(
                    current_acc,
                    current_sess, 
                    current_text, 
                    current_file_ids, 
                    req.model, 
                    chat_id, 
                    created_time, 
                    req.stream
                ):
                    yield chunk
                break 

            except (httpx.ConnectError, httpx.ReadTimeout, ssl.SSLError, HTTPException) as e:
                retry_count += 1
                status_code = e.status_code if isinstance(e, HTTPException) else None
                error_detail = str(e)
                
                logger.warning(f"âš ï¸ è¯·æ±‚å¼‚å¸¸ (é‡è¯• {retry_count}/{max_retries}): {error_detail}")

                # ğŸ”¥ ä½¿ç”¨é€šç”¨å‡½æ•°å¤„ç†è‡ªåŠ¨ç¦ç”¨
                if retry_count >= max_retries:
                    await auto_disable_account_if_needed(current_acc, e, session_pool, "API_CALL")

                if retry_count <= max_retries:
                    # å°è¯•åˆ‡æ¢è´¦å·æˆ–é‡å»º Session
                    if status_code == 401 and current_acc.id > 0:
                        # 401 é”™è¯¯ï¼šå°è¯•åˆ‡æ¢åˆ°å…¶ä»–å¯ç”¨è´¦å·
                        logger.info("ğŸ”„ æ£€æµ‹åˆ° 401ï¼Œå°è¯•åˆ‡æ¢è´¦å·...")
                        new_acc = await account_pool.get_next_account()
                        if new_acc and new_acc.id != current_acc.id:
                            logger.info(f"âœ… åˆ‡æ¢åˆ°è´¦å· [{new_acc.id}] {new_acc.name}")
                            current_acc = new_acc
                        else:
                            logger.warning("âš ï¸ æ— å…¶ä»–å¯ç”¨è´¦å·ï¼Œç»§ç»­é‡å»º Session")
                    else:
                        # å…¶ä»–é”™è¯¯ï¼šé‡å»º Session
                        logger.info("ğŸ”„ å°è¯•é‡å»º Session...")
                    
                    try:
                        new_sess = await create_google_session(current_acc)
                        
                        # æ›´æ–°ä¼šè¯æ± 
                        session_pool.put_session(conv_key, new_sess, current_acc.id)
                        
                        current_sess = new_sess
                        current_retry_mode = True 
                        current_file_ids = [] 
                    except Exception as create_err:
                        logger.error(f"âŒ é‡å»ºå¤±è´¥: {create_err}")
                        if req.stream: yield f"data: {json.dumps({'error': {'message': 'Session Recovery Failed'}})}\n\n"
                        return
                else:
                    if req.stream: yield f"data: {json.dumps({'error': {'message': f'Final Error: {error_detail}'}})}\n\n"
                    return

    if req.stream:
        return StreamingResponse(response_wrapper(), media_type="text/event-stream")
    
    full_content = ""
    async for chunk_str in response_wrapper():
        if chunk_str.startswith("data: [DONE]"): break
        if chunk_str.startswith("data: "):
            try:
                data = json.loads(chunk_str[6:])
                delta = data["choices"][0]["delta"]
                if "content" in delta: full_content += delta["content"]
            except: pass

    return {
        "id": chat_id,
        "object": "chat.completion",
        "created": created_time,
        "model": req.model,
        "choices": [{"index": 0, "message": {"role": "assistant", "content": full_content}, "finish_reason": "stop"}],
        "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
    }

# ---------- JSON Stream Parser ----------
class JSONStreamParser:
    def __init__(self):
        self.buffer_list = [] # Optimization: Use list for O(1) appends
        self.brace_count = 0
        self.in_string = False
        self.escape = False
        self.started = False 

    def process_chunk(self, chunk: str) -> List[str]:
        results = []
        for char in chunk:
            if not self.started:
                if char == '{':
                    self.started = True
                    self.brace_count = 1
                    self.buffer_list = ["{"]
                continue
            
            self.buffer_list.append(char)
            
            if self.in_string:
                if self.escape:
                    self.escape = False
                elif char == '\\':
                    self.escape = True
                elif char == '"':
                    self.in_string = False
            else:
                if char == '"':
                    self.in_string = True
                elif char == '{':
                    self.brace_count += 1
                elif char == '}':
                    self.brace_count -= 1
                    if self.brace_count == 0:
                        results.append("".join(self.buffer_list))
                        self.buffer_list = []
                        self.started = False
        return results

async def stream_chat_generator(account: Account, session: str, text_content: str, file_ids: List[str], model_name: str, chat_id: str, created_time: int, is_stream: bool = True):
    jwt = await account.get_jwt()
    headers = get_common_headers(jwt)
    
    body = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "streamAssistRequest": {
            "session": session,
            "query": {"parts": [{"text": text_content}]},
            "filter": "",
            "fileIds": file_ids, 
            "answerGenerationMode": "NORMAL",
            "toolsSpec": {
                "webGroundingSpec": {},
                "toolRegistry": "default_tool_registry",
                "imageGenerationSpec": {},
                "videoGenerationSpec": {}
            },
            "languageCode": "zh-CN",
            "userMetadata": {"timeZone": "Asia/Shanghai"},
            "assistSkippingMode": "REQUEST_ASSIST"
        }
    }

    target_model_id = MODEL_MAPPING.get(model_name)
    if target_model_id:
        body["streamAssistRequest"]["assistGenerationConfig"] = {
            "modelId": target_model_id
        }

    if is_stream:
        chunk = create_chunk(chat_id, created_time, model_name, {"role": "assistant"}, None)
        yield f"data: {chunk}\n\n"

    parser = JSONStreamParser()
    
    # Use incremental decoder to handle multi-byte characters split across chunks
    import codecs
    decoder = codecs.getincrementaldecoder("utf-8")(errors="replace")

    try:
        async with http_client.stream(
            "POST",
            "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetStreamAssist",
            headers=headers,
            json=body,
        ) as response:
            if response.status_code != 200:
                await response.aread()
                raise HTTPException(status_code=response.status_code, detail=f"Upstream Error {response.text}")

            # Smoothness Optimization:
            # The upstream API might return multiple JSON objects in a single chunk or split them.
            # We want to yield as soon as we have a displayable character.
            has_started_responding = False
            
            async for chunk_bytes in response.aiter_bytes(chunk_size=1024): # Try smaller chunks
                # Decode bytes incrementally
                chunk_str = decoder.decode(chunk_bytes, final=False)
                if not chunk_str:
                    continue
                    
                json_objects = parser.process_chunk(chunk_str)
                
                for json_str in json_objects:
                    try:
                        data = json.loads(json_str)
                        # Process the data immediately
                        for reply in data.get("streamAssistResponse", {}).get("answer", {}).get("replies", []):
                            content_obj = reply.get("groundedContent", {}).get("content", {})
                            text = content_obj.get("text", "")
                            
                            is_thought = reply.get("thought", False)
                            
                            # Optimized Filter Logic:
                            # If we haven't started responding yet (first token), we aggressively hide thoughts.
                            # Once valid text appears, we let everything through for speed.
                            
                            if not has_started_responding:
                                if text:
                                    clean_text = text.strip()
                                    # Very basic check for thought markers
                                    if clean_text.startswith("**") and clean_text.endswith("**") and len(clean_text) < 80:
                                        # Likely a thought header like "**Thought**"
                                        is_thought = True
                                    else:
                                        # Passed the filter
                                        has_started_responding = True
                            
                            # If filtered, log debug but don't yield (increases perceived latency but cleans output)
                            if is_thought and not has_started_responding:
                                logger.debug(f"ğŸ’­ Skipping thought: {text[:20]}...")
                                continue
                            
                            if text:
                                has_started_responding = True 
                                chunk = create_chunk(chat_id, created_time, model_name, {"content": text}, None)
                                if is_stream:
                                    yield f"data: {chunk}\n\n"
                                    # Anti-glitch: Small sleep 0 to force IO flush? 
                                    # Usually not needed in asyncio, but good for tight loops
                                    # await asyncio.sleep(0) 
                                else:
                                    pass
                    except json.JSONDecodeError:
                        logger.warning(f"âš ï¸ è§£æ JSON å¤±è´¥: {json_str[:50]}...")
                        continue

    except Exception as e:
        logger.error(f"âŒ æµå¼è¯·æ±‚å¼‚å¸¸: {e}")
        error_chunk = create_chunk(chat_id, created_time, model_name, {"content": f"\n[Error: {str(e)}]"}, "stop")
        if is_stream:
            yield f"data: {error_chunk}\n\n"
        raise e
    
    if is_stream:
        final_chunk = create_chunk(chat_id, created_time, model_name, {}, "stop")
        yield f"data: {final_chunk}\n\n"
        yield "data: [DONE]\n\n"

if __name__ == "__main__":
    if not (API_KEY):
        print("Error: Missing API_KEY variables.")
        exit(1)
    
    # Initialize Check
    if not (ENV_SECURE_C_SES or os.getenv("DATABASE_URL")):
         print("Warning: No Account Configs Found (ENV or DB).")

    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=7860)
